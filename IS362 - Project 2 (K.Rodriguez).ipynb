{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdefb604-ea33-4330-8cfb-3b604552fc17",
   "metadata": {},
   "source": [
    "**============= Project 2 - Datasets for downstream analysis work =============**\n",
    "\n",
    "IS362 - Kelvin Rodriguez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3096356-eba3-4ea3-a3d6-8ff4f2975908",
   "metadata": {},
   "source": [
    "**_Dataset #1 - Lottery Powerball Winning Numbers: Beginning 2010_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa51b11-365f-4607-a737-62f911b0ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "--- Lottery draws for the year 2020 (Sorted by date)\n",
      "=========================================================\n",
      " Draw Date  Multiplier  Ball 1 Ball 2 Ball 3 Ball 4 Ball 5 Bonus Ball\n",
      "2020-01-01         2.0      49     53     57     59     62         26\n",
      "2020-01-04         2.0       1     11     21     25     54         07\n",
      "2020-01-08         4.0       2     04     07     43     56         22\n",
      "2020-01-11         2.0       3     21     23     31     59         03\n",
      "2020-01-15         2.0      39     41     53     55     68         19\n",
      "2020-01-18         2.0      20     24     38     56     68         18\n",
      "2020-01-22         3.0      11     33     44     59     67         08\n",
      "2020-01-25         2.0       2     09     17     36     67         18\n",
      "2020-01-29         2.0       9     12     15     31     60         02\n",
      "2020-02-01         4.0      12     33     54     57     60         13\n",
      "2020-02-05         3.0      23     30     35     41     57         02\n",
      "2020-02-08         2.0      35     49     50     59     66         06\n",
      "2020-02-12         2.0      14     47     54     55     68         25\n",
      "2020-02-15         3.0      16     32     35     36     46         03\n",
      "2020-02-19         2.0      10     12     15     19     56         19\n",
      "2020-02-22         3.0      25     37     39     61     62         11\n",
      "2020-02-26         3.0       8     27     29     36     47         24\n",
      "2020-02-29         3.0      24     44     46     50     51         13\n",
      "2020-03-04         2.0      18     43     58     60     68         14\n",
      "2020-03-07         2.0       7     15     21     33     62         23\n",
      "2020-03-11         4.0       4     29     49     50     67         02\n",
      "2020-03-14         3.0       9     23     26     30     32         08\n",
      "2020-03-18         4.0      15     27     44     59     63         08\n",
      "2020-03-21         2.0       2     23     40     59     69         13\n",
      "2020-03-25         2.0       5     09     27     39     42         16\n",
      "2020-03-28         2.0       7     40     48     55     66         11\n",
      "2020-04-01         2.0      33     35     45     48     60         16\n",
      "2020-04-04         3.0       8     31     39     40     43         04\n",
      "2020-04-08         3.0       2     37     39     48     54         05\n",
      "2020-04-11         3.0      22     29     30     42     47         17\n",
      "2020-04-15         3.0      10     12     33     36     41         02\n",
      "2020-04-18         2.0       4     44     46     56     63         19\n",
      "2020-04-22         5.0       1     33     35     40     69         24\n",
      "2020-04-25         2.0       1     03     21     47     57         18\n",
      "2020-04-29         2.0       2     20     49     61     67         20\n",
      "2020-05-02         5.0      13     16     33     58     68         24\n",
      "2020-05-06         4.0       7     08     35     50     65         20\n",
      "2020-05-09         5.0      12     18     42     48     65         19\n",
      "2020-05-13         3.0      39     53     54     56     57         20\n",
      "2020-05-16         2.0       8     12     26     39     42         11\n",
      "2020-05-20         2.0      18     34     40     42     50         09\n",
      "2020-05-23         4.0       2     08     18     21     23         16\n",
      "2020-05-27         3.0      38     58     59     64     68         21\n",
      "2020-05-30         2.0      13     32     41     58     60         14\n",
      "2020-06-03         2.0       1     03     26     41     64         17\n",
      "2020-06-06         2.0       1     17     38     68     69         18\n",
      "2020-06-10         5.0      10     33     41     52     54         18\n",
      "2020-06-13         3.0       2     12     32     50     65         05\n",
      "2020-06-17         3.0       7     10     63     64     68         10\n",
      "2020-06-20         3.0      10     31     41     63     67         05\n",
      "2020-06-24         3.0      15     22     27     33     46         23\n",
      "2020-06-27         2.0       9     36     49     56     62         08\n",
      "2020-07-01         4.0      15     28     52     53     63         18\n",
      "2020-07-04         2.0      16     21     27     60     61         06\n",
      "2020-07-08        10.0       3     10     34     36     62         05\n",
      "2020-07-11         2.0      14     19     61     62     64         04\n",
      "2020-07-15        10.0      27     47     61     62     69         04\n",
      "2020-07-18         2.0      13     16     32     58     59         09\n",
      "2020-07-22         3.0      16     25     36     44     55         14\n",
      "2020-07-25         2.0       5     21     36     61     62         18\n",
      "2020-07-29         2.0       7     29     35     40     45         26\n",
      "2020-08-01         3.0       6     25     36     43     48         24\n",
      "2020-08-05         5.0       7     14     17     57     65         24\n",
      "2020-08-08         3.0       2     03     14     40     51         24\n",
      "2020-08-12         2.0       2     06     18     36     37         21\n",
      "2020-08-15         3.0       5     12     34     45     56         03\n",
      "2020-08-19        10.0      13     23     47     55     58         23\n",
      "2020-08-22         3.0      19     30     36     42     66         14\n",
      "2020-08-26         2.0       8     12     19     47     58         02\n",
      "2020-08-29         2.0       5     21     22     29     43         10\n",
      "2020-09-02         2.0       1     04     11     20     69         18\n",
      "2020-09-05         2.0      15     21     22     27     47         07\n",
      "2020-09-09         3.0      27     52     55     60     64         21\n",
      "2020-09-12         2.0      16     17     20     53     67         04\n",
      "2020-09-16         2.0      10     17     31     51     53         01\n",
      "2020-09-19         4.0      11     14     23     47     57         14\n",
      "2020-09-23         2.0       8     17     49     52     59         01\n",
      "2020-09-26         3.0      11     21     27     36     62         24\n",
      "2020-09-30         2.0      14     18     36     49     67         18\n",
      "2020-10-03         2.0      18     31     36     43     47         20\n",
      "2020-10-07         2.0       6     24     30     53     56         19\n",
      "2020-10-10         3.0       5     18     23     40     50         18\n",
      "2020-10-14         2.0      21     37     52     53     58         05\n",
      "2020-10-17         2.0       6     10     31     37     44         23\n",
      "2020-10-21         3.0       1     03     13     44     56         26\n",
      "2020-10-24         2.0      18     20     27     45     65         06\n",
      "2020-10-28         2.0      11     28     37     40     53         13\n",
      "2020-10-31         3.0       2     06     40     42     55         24\n",
      "2020-11-04         2.0      23     32     33     45     49         14\n",
      "2020-11-07         2.0      14     16     37     48     58         18\n",
      "2020-11-11         2.0      13     15     17     45     63         13\n",
      "2020-11-14         2.0       7     15     18     32     45         20\n",
      "2020-11-18         2.0       4     05     17     43     52         05\n",
      "2020-11-21         2.0      51     54     57     60     69         11\n",
      "2020-11-25         2.0       2     57     58     60     65         26\n",
      "2020-11-28         2.0       8     12     18     44     51         18\n",
      "2020-12-02         3.0      28     31     40     41     46         04\n",
      "2020-12-05         2.0       3     04     06     48     53         10\n",
      "2020-12-09         3.0      11     14     31     47     48         04\n",
      "2020-12-12         2.0      17     54     56     63     69         20\n",
      "2020-12-16         2.0       4     23     37     61     67         07\n",
      "2020-12-19         2.0      27     32     34     43     52         13\n",
      "2020-12-23         3.0       6     13     38     39     53         06\n",
      "2020-12-26         2.0      10     24     27     35     53         18\n",
      "2020-12-30         2.0       3     43     45     61     65         14\n",
      "\n",
      "==================================================\n",
      "--- Top 5 Most Common 'Ball 1' Numbers in 2020 ---\n",
      "==================================================\n",
      "Ball 1\n",
      "2     11\n",
      "1      7\n",
      "7      7\n",
      "8      6\n",
      "10     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from the remote CSV file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/KingScanor/IS362-Project_2/refs/heads/main/Lottery_Powerball_Winning_Numbers__Beginning_2010.csv\")\n",
    "\n",
    "# Split 'Winning Numbers' string into separate columns for each ball\n",
    "winning_numbers = df['Winning Numbers'].str.split(' ', expand=True)\n",
    "\n",
    "# Rename the new columns\n",
    "winning_numbers.columns = ['Ball 1', 'Ball 2', 'Ball 3', 'Ball 4', 'Ball 5', 'Bonus Ball']\n",
    "\n",
    "# Drop the original combined column\n",
    "df = df.drop('Winning Numbers', axis=1)\n",
    "\n",
    "# Add the new ball columns to the main DataFrame\n",
    "df = pd.concat([df, winning_numbers], axis=1)\n",
    "\n",
    "# Convert 'Draw Date' column to datetime objects\n",
    "df['Draw Date'] = pd.to_datetime(df['Draw Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Filter the DataFrame to include only draws from the year 2020\n",
    "df_2020 = df[df['Draw Date'].dt.year == 2020].copy()\n",
    "\n",
    "# Convert the 'Ball 1' column to an integer type.\n",
    "# It also allows for numerical operations.\n",
    "df_2020['Ball 1'] = df_2020['Ball 1'].astype(int)\n",
    "\n",
    "# Sort the 2020 data by 'Draw Date'\n",
    "df_2020_sorted = df_2020.sort_values(by='Draw Date', ascending=True)\n",
    "\n",
    "# Print a formatted header\n",
    "print(\"\\n\" + \"=\"*57)\n",
    "print('--- Lottery draws for the year 2020 (Sorted by date)')\n",
    "print(\"=\"*57)\n",
    "\n",
    "# Print the final sorted DataFrame without the index\n",
    "print(df_2020_sorted.to_string(index=False))\n",
    "\n",
    "# .value_counts() counts the frequency of each unique number\n",
    "# .nlargest(5) selects the top 5 by count\n",
    "top_5_ball_1_2020 = df_2020['Ball 1'].value_counts().nlargest(5)\n",
    "\n",
    "# 7. Print the result\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- Top 5 Most Common 'Ball 1' Numbers in 2020 ---\")\n",
    "print(\"=\"*50)\n",
    "print(top_5_ball_1_2020)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0213ca14-6745-46d8-8541-4fa50839a9ee",
   "metadata": {},
   "source": [
    "**Dataset #1 Analysis**\n",
    "\n",
    "The Winning Numbers column was a space-separated string that needed to be cleaned up. It was broken into six columns: Ball 1 to Ball 5 and Bonus Ball. I took out the original column and put the divided columns back together in the DataFrame. To make filtering and sorting easier, the Draw Date was turned into a pandas datetime object. After that, the dataset was filtered to only keep draws from 2020, which made a more focused DataFrame called df_2020. Finally, the data type in the Ball 1 column was changed from string to integer to be sure that counting and analysis were correct. The analysis I implemented looked at how often numbers were in the \"Ball 1\" position during the 2020 drawings. I used the pandas methods .value_counts() to count how many times each unique number appeared and .nlargest(5) to get the five most common values in that place. The output shows how many times these popular \"Ball 1\" numbers came up in 2020. The analysis of 2020 Powerball draws illustrates the frequency distribution of the first ball drawn. The Powerball game is based on chance, but this analysis finds the five numbers that most often showed up in the \"Ball 1\" slot. But it's important to remember that in a random lottery, prior results don't affect future results because each draw is separate. It was very interesting to play with this kind of data. This exercise shows how to structure and clean lottery data and do basic frequency analysis, which is an important part of statistical research.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84362065-8ba5-4f09-92cd-2607a6214b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291c006f-3182-4131-82e8-cabf7781c68c",
   "metadata": {},
   "source": [
    "**_Dataset #2 - Climate Comparison Chart of Boston, USA vs New York City, USA_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bf53cbb-f4d7-4258-a214-e52e69270812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "--- Final Combined Data ---\n",
      "============================\n",
      "   Month           City  Value            Metric\n",
      "0    Jan         Boston   0.77     Snowfall (mm)\n",
      "1    Feb         Boston   1.32     Snowfall (mm)\n",
      "2    Mar         Boston   0.76     Snowfall (mm)\n",
      "3    Apr         Boston   0.19     Snowfall (mm)\n",
      "4    May         Boston   0.00     Snowfall (mm)\n",
      "5    Jun         Boston   0.00     Snowfall (mm)\n",
      "6    Jul         Boston   0.00     Snowfall (mm)\n",
      "7    Aug         Boston   0.00     Snowfall (mm)\n",
      "8    Sep         Boston   0.00     Snowfall (mm)\n",
      "9    Oct         Boston   0.02     Snowfall (mm)\n",
      "10   Nov         Boston   0.10     Snowfall (mm)\n",
      "11   Dec         Boston   0.44     Snowfall (mm)\n",
      "12   Jan  New York City   0.48     Snowfall (mm)\n",
      "13   Feb  New York City   0.85     Snowfall (mm)\n",
      "14   Mar  New York City   0.61     Snowfall (mm)\n",
      "15   Apr  New York City   0.04     Snowfall (mm)\n",
      "16   May  New York City   0.00     Snowfall (mm)\n",
      "17   Jun  New York City   0.00     Snowfall (mm)\n",
      "18   Jul  New York City   0.00     Snowfall (mm)\n",
      "19   Aug  New York City   0.00     Snowfall (mm)\n",
      "20   Sep  New York City   0.00     Snowfall (mm)\n",
      "21   Oct  New York City   0.00     Snowfall (mm)\n",
      "22   Nov  New York City   0.07     Snowfall (mm)\n",
      "23   Dec  New York City   0.25     Snowfall (mm)\n",
      "24   Jan         Boston  -1.65  Temperature (°C)\n",
      "25   Feb         Boston  -1.22  Temperature (°C)\n",
      "26   Mar         Boston   2.10  Temperature (°C)\n",
      "27   Apr         Boston   8.19  Temperature (°C)\n",
      "28   May         Boston  14.49  Temperature (°C)\n",
      "29   Jun         Boston  19.58  Temperature (°C)\n",
      "30   Jul         Boston  23.40  Temperature (°C)\n",
      "31   Aug         Boston  22.57  Temperature (°C)\n",
      "32   Sep         Boston  18.73  Temperature (°C)\n",
      "33   Oct         Boston  12.87  Temperature (°C)\n",
      "34   Nov         Boston   5.90  Temperature (°C)\n",
      "35   Dec         Boston   1.63  Temperature (°C)\n",
      "36   NaN         Boston    NaN  Temperature (°C)\n",
      "37   Jan  New York City  -0.23  Temperature (°C)\n",
      "38   Feb  New York City   0.33  Temperature (°C)\n",
      "39   Mar  New York City   3.97  Temperature (°C)\n",
      "40   Apr  New York City  10.07  Temperature (°C)\n",
      "41   May  New York City  15.79  Temperature (°C)\n",
      "42   Jun  New York City  20.92  Temperature (°C)\n",
      "43   Jul  New York City  24.54  Temperature (°C)\n",
      "44   Aug  New York City  23.53  Temperature (°C)\n",
      "45   Sep  New York City  20.07  Temperature (°C)\n",
      "46   Oct  New York City  14.25  Temperature (°C)\n",
      "47   Nov  New York City   7.20  Temperature (°C)\n",
      "48   Dec  New York City   3.25  Temperature (°C)\n",
      "\n",
      "=====================\n",
      "--- Most Snowfall ---\n",
      "=====================\n",
      "             City Month  Value\n",
      "1          Boston   Feb   1.32\n",
      "13  New York City   Feb   0.85\n",
      "\n",
      "=====================\n",
      "--- Coldest Month ---\n",
      "=====================\n",
      "             City Month  Value\n",
      "24         Boston   Jan  -1.65\n",
      "37  New York City   Jan  -0.23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for the two datasets (snowfall and temperature)\n",
    "snow_url = 'https://raw.githubusercontent.com/KingScanor/IS362-Project_2/refs/heads/main/Snow%20(mm)%20-%20Boston%20vs%20NYC.csv'\n",
    "temp_url = 'https://raw.githubusercontent.com/KingScanor/IS362-Project_2/refs/heads/main/Temperature%20%C2%B0C%20-%20Boston%20vs%20NYC.csv'\n",
    "\n",
    "# Define a function to load data, convert it from wide to long (tidy) format, and add a metric label\n",
    "def tidy_and_label_data(url: str, metric_name: str) -> pd.DataFrame:\n",
    "\n",
    "    try:\n",
    "        df =pd.read_csv(url) # Attempt to load the CSV data from the URL\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {metric_name} data: {e}\") # Print error if loading fails\n",
    "        return pd.DataFrame() # Return an empty DataFrame on error\n",
    "\n",
    "# Use pd.melt to convert the DataFrame from wide (Boston, NYC columns) to long (tidy) format    \n",
    "    df_tidy = df.melt(\n",
    "        id_vars=['Month'],# Keep 'Month' as an identifier\n",
    "        value_vars=['Boston', 'New York City'],# Columns to melt (city values)\n",
    "        var_name='City',# New column for City names\n",
    "        value_name='Value' # New column for the corresponding numerical value\n",
    "    )\n",
    "\n",
    "    df_tidy['Metric'] = metric_name # Add a new column to label the data (e.g., 'Snowfall (mm)')\n",
    "\n",
    "    return df_tidy # Return the cleaned, tidy DataFrame\n",
    "\n",
    "# Process the Snowfall data\n",
    "df_snow_tidy = tidy_and_label_data(snow_url, 'Snowfall (mm)')\n",
    "\n",
    "# Process the Temperature data\n",
    "df_temp_tidy = tidy_and_label_data(temp_url, 'Temperature (°C)')\n",
    "\n",
    "# Combine the tidy Snowfall and Temperature DataFrames vertically\n",
    "df_master_tidy = pd.concat([df_snow_tidy, df_temp_tidy], ignore_index=True)\n",
    "\n",
    "# Print the final combined dataset for inspection\n",
    "print(\"\\n\" + \"=\"*28)\n",
    "print(\"--- Final Combined Data ---\")\n",
    "print(\"=\"*28)\n",
    "print(df_master_tidy.head(49))\n",
    "\n",
    "# --- Analysis: Find Max Snowfall ---\n",
    "\n",
    "# Filter the master DataFrame to get only Snowfall data\n",
    "df_snow = df_master_tidy[df_master_tidy['Metric'] == 'Snowfall (mm)']\n",
    "\n",
    "# Find the index of the maximum 'Value' (snowfall) for each 'City'\n",
    "idx_snow = df_snow.groupby('City')['Value'].idxmax()\n",
    "\n",
    "# Use the found indices to retrieve the full rows corresponding to the max snowfall\n",
    "result_snow = df_snow.loc[idx_snow]\n",
    "\n",
    "# --- Analysis: Find Min Temperature (Coldest Month) ---\n",
    "\n",
    "# Filter the master DataFrame to get only Temperature data\n",
    "df_temp = df_master_tidy[df_master_tidy['Metric'] == 'Temperature (°C)']\n",
    "\n",
    "# Find the index of the minimum 'Value' (temperature) for each 'City'\n",
    "idx_temp = df_temp.groupby('City')['Value'].idxmin()\n",
    "\n",
    "# Use the found indices to retrieve the full rows corresponding to the coldest month\n",
    "result_temp = df_temp.loc[idx_temp]\n",
    "\n",
    "# Print the maximum snowfall results\n",
    "print(\"\\n\" + \"=\"*21)\n",
    "print(\"--- Most Snowfall ---\")\n",
    "print(\"=\"*21)\n",
    "print(result_snow[['City', 'Month', 'Value']])\n",
    "\n",
    "# Print the minimum temperature (coldest month) results\n",
    "print(\"\\n\" + \"=\"*21)\n",
    "print(\"--- Coldest Month ---\")\n",
    "print(\"=\"*21)\n",
    "print(result_temp[['City', 'Month', 'Value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf3dfe-387d-4d3e-bab5-182a17cf0673",
   "metadata": {},
   "source": [
    "**Dataset #2 Analysis**\n",
    "\n",
    "To clean up the data, I had to combine two independent datasets that showed the average monthly snowfall and temperature in Boston and New York City.  The goal of the cleanup was to make the DataFrame tidy enough for analysis.  The pd.melt() function was used to change the data from wide to long format. This made three columns: Month, City, and Value.  Before putting the datasets together, a new column named Metric was created to show what kind of measurement it was.  Finally, the two tidy DataFrames were combined into a master DataFrame, which made it possible to see all of the observations for both cities and metrics in one place.  The analysis of extreme weather measures looked at the months in Boston and New York City that had the most snow and the coldest temperatures.  To find the heaviest snowfall for both cities, the data was filtered to only include \"Snowfall (mm)\" values. Then, the largest value was found using the .groupby('City')['Value'].idxmax() function.  For temperature, on the other hand, the study employed idxmin() to discover the month with the lowest temperature.  This approach correctly found the month with the lowest temperature in each city.  This whole process shows how to prepare data quickly using the tidy data philosophy in pandas, which makes it easy to filter and do descriptive statistical analysis on many metrics and categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff8fe3-cb7c-4477-9419-a3482d886ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3904d9ea-974f-446c-9906-92ac3a952d6d",
   "metadata": {},
   "source": [
    "**_Dataset #3 - UN Forecast 2024_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2224134-26db-4a81-bf2e-c3ab18486c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "--- UN Forecast 2024 ---\n",
      "==============================\n",
      "                Country        2024        2030        2050         2100\n",
      "0           Afghanistan  42,647,492  50,039,402  76,885,134  130,216,739\n",
      "1               Albania   2,791,765   2,671,885   2,240,166    1,184,997\n",
      "2               Algeria  46,814,308  50,154,166  59,565,554   64,487,527\n",
      "3        American Samoa      46,765      42,958      37,545       32,293\n",
      "4               Andorra      81,938      85,682      82,195       47,222\n",
      "5                Angola  37,885,849  45,160,458  74,295,394  150,045,574\n",
      "6              Anguilla      14,598      14,977      14,552        9,309\n",
      "7   Antigua and Barbuda      93,772      96,000      95,055       67,975\n",
      "8             Argentina  45,696,159  46,585,022  48,308,944   38,255,990\n",
      "9               Armenia   2,973,840   2,851,291   2,495,207    1,692,198\n",
      "\n",
      "Total rows for UN Forecast 2024: 237\n",
      "\n",
      "=========================================================\n",
      "--- Final Organized Data (Country, Year, Population) ---\n",
      "=========================================================\n",
      "                Country  Year  Population\n",
      "0           Afghanistan  2024    42647492\n",
      "1               Albania  2024     2791765\n",
      "2               Algeria  2024    46814308\n",
      "3        American Samoa  2024       46765\n",
      "4               Andorra  2024       81938\n",
      "5                Angola  2024    37885849\n",
      "6              Anguilla  2024       14598\n",
      "7   Antigua and Barbuda  2024       93772\n",
      "8             Argentina  2024    45696159\n",
      "9               Armenia  2024     2973840\n",
      "\n",
      "Total rows in organized data: 948\n",
      "\n",
      "==================================================\n",
      "--- Top 10 Most Populated Countries in 2030 ---\n",
      "==================================================\n",
      "          Country  Year  Population\n",
      "0           India  2030  1514994080\n",
      "1           China  2030  1415605906\n",
      "2   United States  2030   352162301\n",
      "3       Indonesia  2030   292150100\n",
      "4        Pakistan  2030   274029836\n",
      "5         Nigeria  2030   262580426\n",
      "6          Brazil  2030   223908968\n",
      "7      Bangladesh  2030   184424144\n",
      "8        Ethiopia  2030   149296378\n",
      "9          Russia  2030   141432741\n",
      "\n",
      "Total rows for 2030: 237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the URL for the raw population forecast data\n",
    "url = \"https://raw.githubusercontent.com/KingScanor/IS362-Project_2/refs/heads/main/UN%20Forecast%202024.csv\"\n",
    "\n",
    "try:\n",
    "    df_UN_Forecast_2024 = pd.read_csv(url) # Attempt to read the CSV into a DataFrame\n",
    "    \n",
    "     # Display the first few rows of the raw data\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"--- UN Forecast 2024 ---\")\n",
    "    print(\"=\"*30)\n",
    "    print(df_UN_Forecast_2024.head(10))\n",
    "    print(f\"\\nTotal rows for UN Forecast 2024: {len(df_UN_Forecast_2024)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error Loading CSV: {e}\") # Handle case where CSV loading fails\n",
    "\n",
    "# Convert the DataFrame from wide format (years as columns) to long/tidy format\n",
    "df_organized = pd.melt(\n",
    "    df_UN_Forecast_2024, # The input DataFrame\n",
    "    id_vars=id_cols, # Columns to keep fixed (Country/Region, Subregion, Region)\n",
    "    value_vars=year_cols, # Columns to melt (all the year columns)\n",
    "    var_name='Year', # New column to hold the original column names (the years)\n",
    "    value_name='Population' # New column to hold the values (the population numbers)\n",
    ")\n",
    "\n",
    "# Clean the 'Population' column: Convert to string, remove commas (thousands separator)\n",
    "df_organized['Population'] = (\n",
    "    df_organized['Population']\n",
    "    .astype(str)\n",
    "    .str.replace(',', '', regex=False)\n",
    ")\n",
    "\n",
    "# Convert 'Population' to numeric, handling errors (like non-numeric strings) by setting them to NaN, then convert to integer type\n",
    "df_organized['Population'] = pd.to_numeric(df_organized['Population'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert 'Year' column from string (from melt operation) to integer type\n",
    "df_organized['Year'] = pd.to_numeric(df_organized['Year']).astype(int)\n",
    "\n",
    "# Remove any rows where the 'Population' value is missing (NaN) after cleaning/conversion\n",
    "df_organized = df_organized.dropna(subset=['Population'])\n",
    "\n",
    "# Display the final cleaned and organized data structure\n",
    "print(\"\\n\" + \"=\"*57)\n",
    "print(\"--- Final Organized Data (Country, Year, Population) ---\")\n",
    "print(\"=\"*57)\n",
    "print(df_organized.head(10))\n",
    "print(f\"\\nTotal rows in organized data: {len(df_organized)}\")\n",
    "\n",
    "# Filter the organized DataFrame to include only the year 2030\n",
    "df_2030 = df_organized[df_organized['Year'] == 2030]\n",
    "\n",
    "# Sort the 2030 data by 'Population' in descending order (highest first)\n",
    "df_most_populated_2030 = df_2030.sort_values(\n",
    "    by='Population',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# Print the top 10 most populated countries for the year 2030\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- Top 10 Most Populated Countries in 2030 ---\")\n",
    "print(\"=\"*50)\n",
    "print (df_most_populated_2030.head(10).reset_index(drop=True))\n",
    "print(f\"\\nTotal rows for 2030: {len(df_2030)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31d26eb0-ef69-4a6e-a8dc-97674aac856d",
   "metadata": {},
   "source": [
    "**Dataset #3 Analysis**\n",
    "\n",
    "This code's goal is to clean, restructure, and analyze the UN World Population Forecast data by changing it from a wide format (with years as columns) to a tidy long format (with one nation per row every year). You start by putting the CSV file into a DataFrame and looking at how it is set up. Then you use the pd.melt() function to change the shape of the data. Key identifiers, such as \"Country/Region,\" stay the same, but year columns are combined into a Year and Population format. When cleaning data, you have to deal with missing data and change Population values from strings to numbers. Lastly, entries that aren't numbers are deleted so that only legitimate numeric forecasts stay. The analysis goes into detail about how to get and rank demographic data for 2030. By filtering the df_organized DataFrame to include just forecast data for that year, you can make a DataFrame called df_2030. The data is then sorted by the Population column in reverse order, which gives us a list of the Top 10 Most Populated Countries in 2030 based on UN forecasts. This approach shows how to efficiently handle large datasets to answer specific forecasting questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317bc15b-db03-447c-be4b-82471dfd4af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "066cdc9a-fd38-4597-ab44-5bc03539b14f",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "ClimeChart.com & ClimeChart.com - Michael Caviglia. (n.d.). Boston vs New York City Climate Chart | Weather Overview of Boston, USA and New York City, USA. https://www.climechart.com/en/climate-compare/boston/united-states-of-america/new-york-city/united-states-of-america \n",
    "\n",
    "Compare text and find differences online or offline - Diffchecker. (n.d.). https://www.diffchecker.com/text-compare/ \n",
    "\n",
    "Data.gov. (2025, October 4). State of New York - Lottery Powerball winning numbers: Beginning 2010. https://catalog.data.gov/dataset/lottery-powerball-winning-numbers-beginning-2010 \n",
    "\n",
    "Tidy data in Python · Jean-Nicholas Hould. (n.d.). https://www.jeannicholashould.com/tidy-data-in-python.html \n",
    "\n",
    "User Guide — pandas 2.3.3 documentation. (n.d.). https://pandas.pydata.org/docs/user_guide/index.html Wikipedia contributors. (2025, July 12). List of countries by past and projected future population. \n",
    "\n",
    "Wikipedia. https://en.wikipedia.org/wiki/List_of_countries_by_past_and_projected_future_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa5f08-2318-4f12-b1e2-892d3f0e963f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
